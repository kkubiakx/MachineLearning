{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sat Oct  8 17:46:12 2022\n",
    "\n",
    "@author: Kuba\n",
    "\n",
    "This example uses code from the University of Warsaw educational materials:\n",
    "https://colab.research.google.com/drive/1QTOK6B8jPrP3J7NW2I93q3WZJ1CAWN_H\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.datasets import make_circles\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC \n",
    "import numpy as np\n",
    "\n",
    "# generating a 'circularly distributed' dataset and target class labels\n",
    "X, y = make_circles(500, factor=.1, noise=.1)\n",
    "\n",
    "# scatter plot of the training data\n",
    "ax = plt.gca()\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap=plt.cm.Set1, edgecolor=\"k\")\n",
    "ax.set_xlabel('Some feature 1')\n",
    "ax.set_ylabel('Some feature 2')\n",
    "\n",
    "# creating an instance of the support vector machine classifier\n",
    "# with a radial basis function type of kernel (nonlinear)\n",
    "svm = SVC(kernel='rbf', C=1E10)\n",
    "\n",
    "# training\n",
    "svm.fit(X, y)\n",
    "\n",
    "# grid of points for drawing the nonlinear decision boundary\n",
    "xlim = ax.get_xlim()\n",
    "ylim = ax.get_ylim()\n",
    "xx = np.linspace(xlim[0], xlim[1], 30)\n",
    "yy = np.linspace(ylim[0], ylim[1], 30)\n",
    "YY, XX = np.meshgrid(yy, xx)\n",
    "xy = np.vstack([XX.ravel(), YY.ravel()]).T\n",
    "\n",
    "# drawing the decision bounary (black line) and margins (blue line) using the .decision_function() method\n",
    "Z = svm.decision_function(xy).reshape(XX.shape)\n",
    "ax.contour(XX, YY, Z, colors=['b', 'k', 'b'], levels=[-1, 0, 1], alpha=1,\n",
    "           linestyles=['--', '-', '--'])\n",
    "\n",
    "# mark support vectors (black crosses)\n",
    "support_vector1 = svm.support_vectors_[:, 0]\n",
    "support_vector2 = svm.support_vectors_[:, 1]\n",
    "ax.scatter(support_vector1, support_vector2, s=50,\n",
    "           linewidth=1, color='k', marker = 'x')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Oct  5 12:06:04 2022\n",
    "\n",
    "@author: Kuba\n",
    "\"\"\"\n",
    "\n",
    "# Task: modify the example below\n",
    "# to predict sepal width based on two other features â€“ \n",
    "# sepal length (0) and petal length (2). Fill in the program in places marked\n",
    "# with !!!. In your report, note the values of the learned line parameters and \n",
    "# show the plot\n",
    "\n",
    "# THE CODE LACKS:\n",
    "    # an import of the proper submodule from sklearn that containes linear models\n",
    "    # a definition of the X array containing examples of class 0 (setosa) and the first\n",
    "    # three features only\n",
    "    # a definition of the linear regression object, to be named multiregr\n",
    "    # a line of code to train the model\n",
    "\n",
    "# importing necessary modules\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# !!!\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "X = iris.data\n",
    "labels = iris.target\n",
    "\n",
    "# take only examples from class 0 (iris setosa) and first 3 features\n",
    "# !!!\n",
    "\n",
    "# random ordering of samples\n",
    "random0 = np.random.choice(np.arange(0,50),50,replace=False)\n",
    "\n",
    "# test and training set example indices\n",
    "train_inds = random0[:40]\n",
    "test_inds = random0[40:]\n",
    "\n",
    "# create the regression model and train it\n",
    "# !!!\n",
    "# !!!\n",
    "\n",
    "# check the learned parameters\n",
    "print(multiregr.coef_, multiregr.intercept_) \n",
    "\n",
    "# feature value ranges (for the plot)\n",
    "x_min, x_max = X[train_inds, 0].min() - 0.5, X[train_inds, 0].max() + 0.5\n",
    "x_min2, x_max2 = X[train_inds, 2].min() - 0.5, X[train_inds, 2].max() + 0.5\n",
    "\n",
    "# create a grid of points (x,y) according to the data value ranges\n",
    "x, y = np.meshgrid(np.arange(x_min,x_max,0.5), np.arange(x_min2,x_max2,0.5))\n",
    "surface_points = np.stack([np.ravel(x), np.ravel(y)],1)\n",
    "\n",
    "# predict the dependent variable value\n",
    "z = multiregr.predict(surface_points).reshape(x.shape)\n",
    "\n",
    "# 3D graph\n",
    "fig = plt.figure(figsize=plt.figaspect(1)*2)\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.scatter(X[train_inds, 0],X[train_inds, 2],  X[train_inds, 1],label = \"Training examples\")\n",
    "ax.scatter(X[test_inds, 0],X[test_inds, 2],  X[test_inds, 1], label = \"Test examples\")\n",
    "ax.plot_surface(x, y, z,  color = 'r', alpha = 0.4)\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"Sepal length\")\n",
    "ax.set_ylabel(\"Petal length\")\n",
    "ax.set_zlabel(\"Sepal width (dependent variable)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Oct  5 13:07:53 2022\n",
    "\n",
    "@author: Kuba\n",
    "\"\"\"\n",
    "\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "\n",
    "x_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5\n",
    "y_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "scatter = ax.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Set1, edgecolor=\"k\")\n",
    "plt.xlabel(\"sepal length\")\n",
    "plt.ylabel(\"sepal width\")\n",
    "\n",
    "legend1 = ax.legend(*scatter.legend_elements(),loc=\"lower right\", title=\"Class\")\n",
    "ax.add_artist(legend1)\n",
    "\n",
    "plt.xlim(x_min, x_max)\n",
    "plt.ylim(y_min, y_max)\n",
    "\n",
    "\n",
    "# indices 0-49, 50-99, 100-149 in random order\n",
    "random0 = np.random.choice(np.arange(0,50),50,replace=False)\n",
    "random1 = np.random.choice(np.arange(50,100),50,replace=False)\n",
    "random2 = np.random.choice(np.arange(100,150),50,replace=False)\n",
    "\n",
    "# take 80% (40 samples) of each class to the training set\n",
    "\n",
    "X0 = X[random0[:40],:]\n",
    "X1 = X[random1[:40],:]\n",
    "X2 = X[random2[:40],:]\n",
    "\n",
    "# take the corresponding labels\n",
    "y0 = y[random0[:40]]\n",
    "y1 = y[random1[:40]]\n",
    "y2 = y[random2[:40]]\n",
    "\n",
    "# take 20% (10 samples) of each class to the test set\n",
    "X0_test = X[random0[40:],:]\n",
    "X1_test = X[random1[40:],:]\n",
    "X2_test = X[random2[40:],:]\n",
    "\n",
    "# take the corresponding labels\n",
    "y0_test = y[random0[40:]]\n",
    "y1_test = y[random1[40:]]\n",
    "y2_test = y[random2[40:]]\n",
    "\n",
    "# compose the training set and the test set - just features 0 and 1 and classes 0 and 1\n",
    "X01_train = np.concatenate([X0[:,0:2], X1[:,0:2]])\n",
    "y01_train = np.concatenate([y0, y1])\n",
    "X01_test = np.concatenate([X0_test[:,0:2], X1_test[:,0:2]])\n",
    "y01_test = np.concatenate([y0_test, y1_test])\n",
    "\n",
    "# linear binary classification with a logistic regression model\n",
    "clf = LogisticRegression(random_state=0).fit(X01_train, y01_train)\n",
    "\n",
    "# read the logistic regression model parameters\n",
    "b = clf.intercept_[0]\n",
    "w1, w2 = clf.coef_.T\n",
    "\n",
    "# calculate the intercept and gradient of the decision boundary.\n",
    "c = -b/w2\n",
    "m = -w1/w2\n",
    "\n",
    "# plot the data and the classification with the decision boundary.\n",
    "xmin, xmax = np.min(X01_train,0)[0]-1, np.max(X01_train,0)[0]+1\n",
    "ymin, ymax = np.min(X01_train,0)[1]-1, np.max(X01_train,0)[1]+1\n",
    "\n",
    "xd = np.array([xmin, xmax])\n",
    "yd = m*xd + c\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(xd, yd, 'k', lw=1, ls='--')\n",
    "plt.fill_between(xd, yd, ymin, color='tab:blue', alpha=0.2)\n",
    "plt.fill_between(xd, yd, ymax, color='tab:orange', alpha=0.2)\n",
    "\n",
    "plt.scatter(*X01_train.T, c=y01_train, cmap=plt.cm.Set1, edgecolor=\"k\")\n",
    "plt.scatter(*X01_test.T, c=y01_test, cmap=plt.cm.Set1, edgecolor=\"b\")\n",
    "\n",
    "plt.xlim(xmin, xmax)\n",
    "plt.ylim(ymin, ymax)\n",
    "plt.ylabel(r'sepal width')\n",
    "plt.xlabel(r'sepal length')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
